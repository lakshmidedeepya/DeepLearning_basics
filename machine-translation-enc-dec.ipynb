{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ec40df",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-30T07:20:57.869248Z",
     "iopub.status.busy": "2025-06-30T07:20:57.868986Z",
     "iopub.status.idle": "2025-06-30T07:21:02.827650Z",
     "shell.execute_reply": "2025-06-30T07:21:02.826770Z"
    },
    "papermill": {
     "duration": 4.963347,
     "end_time": "2025-06-30T07:21:02.829057",
     "exception": false,
     "start_time": "2025-06-30T07:20:57.865710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted translation: <pad> bonjour bonjour bonjour bonjour bonjour bonjour bonjour bonjour bonjour\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Vocabulary Setup\n",
    "# ---------------------------------------------\n",
    "SRC_VOCAB = {'<pad>': 0, '<eos>': 1, 'hello': 2, 'hi': 3}\n",
    "TRG_VOCAB = {'<pad>': 0, '<eos>': 1, 'bonjour': 2, 'salut': 3}\n",
    "\n",
    "SRC_itos = {v: k for k, v in SRC_VOCAB.items()}\n",
    "TRG_itos = {v: k for k, v in TRG_VOCAB.items()}\n",
    "\n",
    "INPUT_DIM = len(SRC_VOCAB)\n",
    "OUTPUT_DIM = len(TRG_VOCAB)\n",
    "EMB_DIM = 8\n",
    "HID_DIM = 16\n",
    "\n",
    "# Sample tokenized source (hello <eos>)\n",
    "src_sentence = torch.tensor([[SRC_VOCAB['hello'], SRC_VOCAB['<eos>']]], dtype=torch.long)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Encoder\n",
    "# ---------------------------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden  # (1, batch, hid_dim)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Decoder\n",
    "# ---------------------------------------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.unsqueeze(1)  # (batch, 1)\n",
    "        embedded = self.embedding(input)  # (batch, 1, emb_dim)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc_out(output.squeeze(1))  # (batch, output_dim)\n",
    "        return prediction, hidden\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Seq2Seq Wrapper with Inference\n",
    "# ---------------------------------------------\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, max_len=10):\n",
    "        batch_size = src.shape[0]\n",
    "        hidden = self.encoder(src)\n",
    "        \n",
    "        # Start with <eos> or custom <sos> token\n",
    "        input_token = torch.tensor([TRG_VOCAB['<eos>']], dtype=torch.long).to(self.device)\n",
    "\n",
    "        translated_tokens = []\n",
    "        for _ in range(max_len):\n",
    "            output, hidden = self.decoder(input_token, hidden)\n",
    "            top1 = output.argmax(1)  # Greedy decoding\n",
    "            if top1.item() == TRG_VOCAB['<eos>']:\n",
    "                break\n",
    "            translated_tokens.append(top1.item())\n",
    "            input_token = top1  # Next input is current prediction\n",
    "\n",
    "        return translated_tokens\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Run Translation\n",
    "# ---------------------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = Encoder(INPUT_DIM, EMB_DIM, HID_DIM).to(device)\n",
    "decoder = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM).to(device)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Inference\n",
    "src_sentence = src_sentence.to(device)\n",
    "predicted_indices = model(src_sentence)\n",
    "\n",
    "# Convert indices back to words\n",
    "translated_sentence = [TRG_itos[idx] for idx in predicted_indices]\n",
    "print(\"Predicted translation:\", ' '.join(translated_sentence))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.736536,
   "end_time": "2025-06-30T07:21:04.450848",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-30T07:20:53.714312",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
