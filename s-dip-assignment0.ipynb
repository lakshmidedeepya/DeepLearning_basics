{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce855073",
   "metadata": {
    "_cell_guid": "399bb24e-6a74-4f42-b540-11ec4a07808b",
    "_uuid": "d86a0205-687e-44a1-99c3-400865c45883",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003219,
     "end_time": "2025-08-11T17:18:28.604038",
     "exception": false,
     "start_time": "2025-08-11T17:18:28.600819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Read an image file into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeca918f",
   "metadata": {
    "_cell_guid": "78be716b-7cfc-4cde-b7a2-6debcfc2442f",
    "_uuid": "e0e63f80-f58d-4bc2-b0bf-9b9aaa670e1b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-11T17:18:28.610291Z",
     "iopub.status.busy": "2025-08-11T17:18:28.610048Z",
     "iopub.status.idle": "2025-08-11T17:18:29.088426Z",
     "shell.execute_reply": "2025-08-11T17:18:29.087581Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.482606,
     "end_time": "2025-08-11T17:18:29.089552",
     "exception": false,
     "start_time": "2025-08-11T17:18:28.606946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image '/kaggle/input/dedeepya-images-ds/ds/My_image_color.jpeg' read into array with shape: (960, 1280, 3)\n",
      "Array Successfully written to './0001_color.png'\n",
      "Image '/kaggle/input/colour-greyscale-dataset/data/Flowers/flowers_grey/0005.png' read into array with shape: (128, 128, 4)\n",
      "Array Successfully written to './0005_grey.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def read_image_to_array(filepath):\n",
    "    try:\n",
    "        img=Image.open(filepath)\n",
    "        #convert image to numpy array\n",
    "        img_array=np.array(img)\n",
    "        print(f\"Image '{filepath}' read into array with shape: {img_array.shape}\")\n",
    "        return img_array\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath} was not found\")\n",
    "        return None\n",
    "def write_array_to_image(array,filepath):\n",
    "    if array is None:\n",
    "        print(\"Error:The input array is None\")\n",
    "        return\n",
    "    try:\n",
    "        #Ensure array is in unsigned 8-bit int and values clipped to 0-255\n",
    "        clipped_array=np.clip(array,0,255).astype(np.uint8)\n",
    "\n",
    "        #create an image from the array\n",
    "        img=Image.fromarray(clipped_array)\n",
    "\n",
    "        #save image to specified file\n",
    "        img.save(filepath)\n",
    "        print(f\"Array Successfully written to '{filepath}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occured while writing the image: {e}\")\n",
    "\n",
    "color_image_array=read_image_to_array('/kaggle/input/dedeepya-images-ds/ds/My_image_color.jpeg')\n",
    "if color_image_array is not None:\n",
    "    write_array_to_image(color_image_array,'./0001_color.png')\n",
    "grey_image_array=read_image_to_array('/kaggle/input/colour-greyscale-dataset/data/Flowers/flowers_grey/0005.png')\n",
    "if grey_image_array is not None:\n",
    "    write_array_to_image(grey_image_array,'./0005_grey.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b69f9c7",
   "metadata": {
    "_cell_guid": "c93cbfd7-d72e-4502-997c-a5ddac622f09",
    "_uuid": "44ec1861-8459-4ec4-8cb1-c14f105bae6b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-11T17:18:29.095958Z",
     "iopub.status.busy": "2025-08-11T17:18:29.095743Z",
     "iopub.status.idle": "2025-08-11T17:18:29.177328Z",
     "shell.execute_reply": "2025-08-11T17:18:29.176420Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.086262,
     "end_time": "2025-08-11T17:18:29.178688",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.092426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image '/kaggle/input/dedeepya-images-ds/ds/My_image_color.jpeg' read into array with shape: (960, 1280, 3)\n",
      "Array Successfully written to 'brighter.jpg'\n",
      "Array Successfully written to 'darker.jpg'\n"
     ]
    }
   ],
   "source": [
    "def change_brightness(image_array,value):\n",
    "    #Use floating point type for the calculation to prevent overflow \n",
    "    #then clip reslt back to valid range 0-255 fr 8-bit image\n",
    "    bright_image_array=np.clip(image_array.astype(np.float32)+value,0,255)\n",
    "\n",
    "    #convert back to original data type\n",
    "    return bright_image_array.astype(bright_image_array.dtype)\n",
    "\n",
    "original_image =read_image_to_array('/kaggle/input/dedeepya-images-ds/ds/My_image_color.jpeg')\n",
    "brighter_image=change_brightness(original_image,50)#inc brightness\n",
    "darker_image=change_brightness(original_image,-50)#dec brightness\n",
    "write_array_to_image(brighter_image,'brighter.jpg')\n",
    "write_array_to_image(darker_image,'darker.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e7ad05",
   "metadata": {
    "_cell_guid": "b4b99006-b8e8-4f3c-8140-7670493df6bb",
    "_uuid": "cea9cb46-e4df-4791-9f1a-0519af01c939",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.002708,
     "end_time": "2025-08-11T17:18:29.184405",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.181697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b519e3",
   "metadata": {
    "_cell_guid": "4e6a5a80-fba4-4295-8af1-8956f375a4ae",
    "_uuid": "1ca16de1-2c97-4dab-95a6-2ea8d38e5e97",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-11T17:18:29.190502Z",
     "iopub.status.busy": "2025-08-11T17:18:29.190242Z",
     "iopub.status.idle": "2025-08-11T17:18:29.262133Z",
     "shell.execute_reply": "2025-08-11T17:18:29.261451Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.076159,
     "end_time": "2025-08-11T17:18:29.263162",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.187003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image '/kaggle/input/dedeepya-images-ds/ds/My_image_color_2.jpeg' read into array with shape: (1280, 960, 3)\n",
      "Array Successfully written to 'high_contrast.jpg'\n",
      "Array Successfully written to 'low_contrast.jpg'\n"
     ]
    }
   ],
   "source": [
    "def change_contrast(image_array, factor):\n",
    "    # Convert to float for calculation\n",
    "    img_float = image_array.astype(np.float32)\n",
    "    \n",
    "    # Apply the contrast formula\n",
    "    contrast_image_array = factor * (img_float - 128) + 128\n",
    "    \n",
    "    # Clip the values to the 0-255 range\n",
    "    contrast_image_array = np.clip(contrast_image_array, 0, 255)\n",
    "    \n",
    "    return contrast_image_array.astype(image_array.dtype)\n",
    "\n",
    "# --- Example Usage ---\n",
    "original_image = read_image_to_array('/kaggle/input/dedeepya-images-ds/ds/My_image_color_2.jpeg')\n",
    "high_contrast = change_contrast(original_image, 1.5) # Increase contrast\n",
    "low_contrast = change_contrast(original_image, 0.7)   # Decrease contrast\n",
    "write_array_to_image(high_contrast, 'high_contrast.jpg')\n",
    "write_array_to_image(low_contrast, 'low_contrast.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b6b7f5",
   "metadata": {
    "_cell_guid": "44d07767-338a-4fc0-9699-2930305f47fa",
    "_uuid": "ebfde30f-184b-4c17-91ba-c08867ab3def",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.002633,
     "end_time": "2025-08-11T17:18:29.268862",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.266229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Average Method**:  Gray= (R+G+B)/3\n",
    "\n",
    "**Luminous Method** :\n",
    "Common weights: 0.299ùëÖ+0.587ùê∫+0.114ùêµ (from ITU-R BT.601 standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71a0106",
   "metadata": {
    "_cell_guid": "70378bf8-0816-4da6-a494-0b571e553840",
    "_uuid": "6e35aee6-60f5-4074-a489-e33bce0a238c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-11T17:18:29.275020Z",
     "iopub.status.busy": "2025-08-11T17:18:29.274835Z",
     "iopub.status.idle": "2025-08-11T17:18:29.470555Z",
     "shell.execute_reply": "2025-08-11T17:18:29.469820Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.200225,
     "end_time": "2025-08-11T17:18:29.471682",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.271457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image '/kaggle/input/dedeepya-images-ds/ds/pics (1).jpeg' read into array with shape: (575, 1280, 3)\n",
      "Array Successfully written to 'gray_luminosity.png'\n",
      "Array Successfully written to 'gray_average.png'\n"
     ]
    }
   ],
   "source": [
    "def color_to_grayscale(image_array, method='luminosity'):\n",
    "    if image_array.ndim != 3 or image_array.shape[2] != 3:\n",
    "        print(\"Error: Input must be a color image (3 channels).\")\n",
    "        return image_array\n",
    "        \n",
    "    R, G, B = image_array[:,:,0], image_array[:,:,1], image_array[:,:,2]\n",
    "    \n",
    "    if method == 'average':\n",
    "        gray_array = (R.astype(float) + G.astype(float) + B.astype(float)) / 3\n",
    "    elif method == 'luminosity':\n",
    "        gray_array = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method. Choose 'average' or 'luminosity'.\")\n",
    "        \n",
    "    return gray_array.astype(image_array.dtype)\n",
    "\n",
    "# --- Example Usage ---\n",
    "color_image = read_image_to_array('/kaggle/input/dedeepya-images-ds/ds/pics (1).jpeg')\n",
    "gray_luminosity = color_to_grayscale(color_image, method='luminosity')\n",
    "gray_average = color_to_grayscale(color_image, method='average')\n",
    "write_array_to_image(gray_luminosity, 'gray_luminosity.png')\n",
    "write_array_to_image(gray_average, 'gray_average.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25bc1c",
   "metadata": {
    "_cell_guid": "dcd67ae7-f3e4-41c1-94b0-ad47d0f8b4f0",
    "_uuid": "40e5dbcc-7831-4695-9381-53fd3661d8dd",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.00277,
     "end_time": "2025-08-11T17:18:29.477592",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.474822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "grey to pseudo-color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1176e19e",
   "metadata": {
    "_cell_guid": "25a21ce5-349b-4921-8434-d286814abd5a",
    "_uuid": "8f9bc763-733c-4e17-9262-2c170efd95e1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-11T17:18:29.484457Z",
     "iopub.status.busy": "2025-08-11T17:18:29.484214Z",
     "iopub.status.idle": "2025-08-11T17:18:29.867985Z",
     "shell.execute_reply": "2025-08-11T17:18:29.867211Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.3887,
     "end_time": "2025-08-11T17:18:29.869148",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.480448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image '/kaggle/working/0001_color.png' read into array with shape: (960, 1280, 3)\n",
      "Array Successfully written to 'pseudo_color.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_pseudocolor(gray_array):\n",
    "    if gray_array.ndim != 2:\n",
    "        raise ValueError(\"Input must be a grayscale image (2D array).\")\n",
    "    \n",
    "    # Ensure uint8\n",
    "    gray_array = gray_array.astype(np.uint8)\n",
    "    \n",
    "    # Create LUT for \"hot\" colormap\n",
    "    lut = np.zeros((256, 3), dtype=np.uint8)\n",
    "    for i in range(256):\n",
    "        if i < 85:\n",
    "            lut[i] = [i * 3, 0, 0]              # Black ‚Üí Red\n",
    "        elif i < 170:\n",
    "            lut[i] = [255, (i - 85) * 3, 0]     # Red ‚Üí Yellow\n",
    "        else:\n",
    "            lut[i] = [255, 255, (i - 170) * 3]  # Yellow ‚Üí White\n",
    "\n",
    "    # Map grayscale values to colors using LUT\n",
    "    color_image = lut[gray_array]\n",
    "    \n",
    "    return color_image\n",
    "\n",
    "# --- Example usage ---\n",
    "gray_image = read_image_to_array('/kaggle/working/0001_color.png')\n",
    "if gray_image.ndim == 3:\n",
    "    gray_image = color_to_grayscale(gray_image)\n",
    "\n",
    "pseudo_color_image = apply_pseudocolor(gray_image)\n",
    "write_array_to_image(pseudo_color_image, 'pseudo_color.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553c15b",
   "metadata": {
    "_cell_guid": "78a276ea-f9ae-4519-bde5-4e99ab5cf04b",
    "_uuid": "0aeb8b5b-cfc1-438f-92bb-fd612174d0b5",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.002719,
     "end_time": "2025-08-11T17:18:29.875208",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.872489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Green Screen Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59c1963",
   "metadata": {
    "_cell_guid": "81dfed9c-66bb-4060-830f-5ed7b1935799",
    "_uuid": "1c7ff552-e755-435d-a7fd-8a07989d08be",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-11T17:18:29.881774Z",
     "iopub.status.busy": "2025-08-11T17:18:29.881565Z",
     "iopub.status.idle": "2025-08-11T17:18:43.264924Z",
     "shell.execute_reply": "2025-08-11T17:18:43.264071Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 13.387951,
     "end_time": "2025-08-11T17:18:43.266083",
     "exception": false,
     "start_time": "2025-08-11T17:18:29.878132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image '/kaggle/input/green-background-ds/smiling-young-caucasian-woman-points.jpg' read into array with shape: (5304, 7521, 3)\n",
      "Image '/kaggle/input/dedeepya-images-ds/ds/pics (3).jpeg' read into array with shape: (575, 1280, 3)\n",
      "Error: Images must have the same dimensions.\n",
      "(5304, 7521)\n",
      "(5304, 7521, 3)\n",
      "Array Successfully written to 'composite_image.png'\n"
     ]
    }
   ],
   "source": [
    "def replace_green_screen(foreground_img, background_img):\n",
    "    \n",
    "    # Ensure images are the same size\n",
    "    if foreground_img.shape != background_img.shape:\n",
    "        print(\"Error: Images must have the same dimensions.\")\n",
    "        # Resize background to match foreground as a fallback\n",
    "        bg_pil = Image.fromarray(background_img)\n",
    "        bg_pil = bg_pil.resize((foreground_img.shape[1], foreground_img.shape[0]))\n",
    "        background_img = np.array(bg_pil)\n",
    "\n",
    "    # Get R, G, B channels of the foreground\n",
    "    R, G, B = foreground_img[:,:,0], foreground_img[:,:,1], foreground_img[:,:,2]\n",
    "    \n",
    "    # Define the green screen condition (this may need tuning)\n",
    "    # A simple but effective condition: G is the dominant channel\n",
    "    # and G is above a certain brightness threshold.\n",
    "    green_mask = (G > 100) & (G > R * 1.2) & (G > B * 1.2)\n",
    "    print(green_mask.shape)\n",
    "    \n",
    "    # Expand the mask from 2D to 3D to work with color images\n",
    "    green_mask_3d = np.stack([green_mask] * 3, axis=-1)\n",
    "    print(green_mask_3d.shape)\n",
    "    \n",
    "    # Use np.where: if mask is True, use background; otherwise, use foreground.\n",
    "    composite_image = np.where(green_mask_3d, background_img, foreground_img)\n",
    "    \n",
    "    return composite_image.astype(np.uint8)\n",
    "\n",
    "# --- Example Usage ---\n",
    "foreground = read_image_to_array('/kaggle/input/green-background-ds/smiling-young-caucasian-woman-points.jpg')\n",
    "background = read_image_to_array('/kaggle/input/dedeepya-images-ds/ds/pics (3).jpeg')\n",
    "result = replace_green_screen(foreground, background)\n",
    "write_array_to_image(result, 'composite_image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d978c",
   "metadata": {
    "_cell_guid": "a7d64d9b-f3e4-4dfc-8ebb-fd67fa7cb8c3",
    "_uuid": "170f60e0-383f-4890-8a1d-303513dea455",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003052,
     "end_time": "2025-08-11T17:18:43.273203",
     "exception": false,
     "start_time": "2025-08-11T17:18:43.270151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Video Processing: Frames to Video and Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc178ae6",
   "metadata": {
    "_cell_guid": "1bbd5943-dcb9-47b6-b701-3f85a1a53a1e",
    "_uuid": "09fd3516-abcd-4aca-95b0-ea107bf66b21",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-11T17:18:43.280214Z",
     "iopub.status.busy": "2025-08-11T17:18:43.279982Z",
     "iopub.status.idle": "2025-08-11T17:18:43.858859Z",
     "shell.execute_reply": "2025-08-11T17:18:43.858120Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.583737,
     "end_time": "2025-08-11T17:18:43.860014",
     "exception": false,
     "start_time": "2025-08-11T17:18:43.276277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image '/kaggle/input/dedeepya-images-ds/ds/pics (1).jpeg' read into array with shape: (575, 1280, 3)\n",
      "Image '/kaggle/input/dedeepya-images-ds/ds/pics (3).jpeg' read into array with shape: (575, 1280, 3)\n",
      "Video saved to fade_transition.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def video_to_frames(video_path):\n",
    "    \"\"\"Reads a video file and returns a list of its frames as NumPy arrays.\"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return []\n",
    "        \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # OpenCV reads in BGR format, so convert to RGB for consistency with Pillow\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame_rgb)\n",
    "        \n",
    "    cap.release()\n",
    "    print(f\"Read {len(frames)} frames from {video_path}\")\n",
    "    return frames\n",
    "\n",
    "def frames_to_video(frames, output_path, fps):\n",
    "    \"\"\"Writes a list of frames to a video file.\"\"\"\n",
    "    if not frames:\n",
    "        print(\"Error: Frame list is empty.\")\n",
    "        return\n",
    "        \n",
    "    H, W, _ = frames[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for .mp4 file\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, fps, (W, H))\n",
    "    \n",
    "    for frame in frames:\n",
    "        # Convert back to BGR for OpenCV writer\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        writer.write(frame_bgr)\n",
    "        \n",
    "    writer.release()\n",
    "    print(f\"Video saved to {output_path}\")\n",
    "\n",
    "def create_fade_transition(img1_path, img2_path, output_path, duration_sec=1, fps=30):\n",
    "    \"\"\"Creates a 1-second fade transition video from image1 to image2.\"\"\"\n",
    "    img1 = read_image_to_array(img1_path)\n",
    "    img2 = read_image_to_array(img2_path)\n",
    "\n",
    "    # Ensure images are the same size\n",
    "    if img1.shape != img2.shape:\n",
    "        print(\"Resizing image2 to match image1 for transition.\")\n",
    "        img2_pil = Image.fromarray(img2).resize((img1.shape[1], img1.shape[0]))\n",
    "        img2 = np.array(img2_pil)\n",
    "\n",
    "    num_frames = int(duration_sec * fps)\n",
    "    transition_frames = []\n",
    "\n",
    "    # Convert to float for accurate blending\n",
    "    img1_float = img1.astype(np.float32)\n",
    "    img2_float = img2.astype(np.float32)\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        alpha = i / (num_frames - 1) # Alpha goes from 0 to 1\n",
    "        \n",
    "        # Alpha blending formula\n",
    "        blended_frame = ((1 - alpha) * img1_float + alpha * img2_float)\n",
    "        \n",
    "        # Convert back to uint8 for saving\n",
    "        transition_frames.append(blended_frame.astype(np.uint8))\n",
    "        \n",
    "    # Write the frames to a video\n",
    "    frames_to_video(transition_frames, output_path, fps)\n",
    "\n",
    "# --- Example Usage ---\n",
    "create_fade_transition('/kaggle/input/dedeepya-images-ds/ds/pics (1).jpeg', '/kaggle/input/dedeepya-images-ds/ds/pics (3).jpeg', 'fade_transition.mp4')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5356366,
     "sourceId": 8908412,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8046848,
     "sourceId": 12730866,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8049102,
     "sourceId": 12734004,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.565202,
   "end_time": "2025-08-11T17:18:44.179954",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-11T17:18:24.614752",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
